# Spearman Correlation Analysis Summary

**Analysis Date:** November 30, 2025  
**Method:** Spearman's rank correlation coefficient (œÅ)  
**Participants:** 15 (Neutral: 5, Opposing: 5, Similar: 5)

---

## Why Spearman Correlation?

‚úÖ **More robust** - Resistant to outliers and extreme values  
‚úÖ **No normality assumption** - Works with non-normal distributions  
‚úÖ **Detects monotonic relationships** - Captures non-linear patterns  
‚úÖ **Rank-based** - Less sensitive to scale and measurement issues  

---

## Overall Results Summary

| Modality | Total Correlations | Significant (p<0.05) | Highly Significant (p<0.01) | Strongest r |
|----------|-------------------|---------------------|----------------------------|------------|
| **Facial** | 780 | 5 (0.6%) | 3 | 0.746 |
| **Voice** | 1,404 | 73 (5.2%) | 33 | 0.769 |
| **Fusion** | 252 | 7 (2.8%) | 4 | 0.866 |

---

## Top 10 Strongest Correlations (Across All Modalities)

### 1. **Fusion: combined_quadrant_transitions ‚Üí Topic_Coverage**
   - œÅ = **0.866** | p = 0.0000 ***
   - Interpretation: Emotional state changes predict topic coverage quality

### 2. **Fusion: combined_quadrant_transitions ‚Üí Overall_Percentage**
   - œÅ = **0.812** | p = 0.0002 ***
   - Interpretation: Overall summary quality increases with emotional dynamics

### 3. **Voice: volume_std_trend_direction ‚Üí Topic_Coverage**
   - œÅ = **0.769** | p = 0.0008 ***
   - Interpretation: Voice volume variability trends predict topic coverage

### 4. **Voice: volume_range_trend_direction ‚Üí Topic_Coverage**
   - œÅ = **0.769** | p = 0.0008 ***
   - Interpretation: Voice volume range trends predict topic coverage

### 5. **Fusion: fused_quadrant_transitions ‚Üí Overall_Percentage**
   - œÅ = **0.748** | p = 0.0013 **
   - Interpretation: Pure fusion transitions predict overall quality

### 6. **Facial: disgust_min ‚Üí Semantic_Similarity**
   - œÅ = **0.746** | p = 0.0014 **
   - Interpretation: Lower disgust baseline associates with better semantic similarity

### 7. **Facial: happy_min ‚Üí Semantic_Similarity**
   - œÅ = **0.725** | p = 0.0022 **
   - Interpretation: Happy baseline predicts semantic quality

### 8. **Fusion: fused_quadrant_transitions ‚Üí Topic_Coverage**
   - œÅ = **0.719** | p = 0.0025 **
   - Interpretation: Fusion-based emotional state changes predict topic coverage

### 9. **Voice: pitch_mean_total_change ‚Üí Topic_Coverage**
   - œÅ = **0.701** | p = 0.0036 **
   - Interpretation: Pitch dynamics correlate with topic coverage

### 10. **Voice: volume_std_trend_direction ‚Üí Overall_Percentage**
   - œÅ = **0.697** | p = 0.0039 **
   - Interpretation: Voice volume trends predict overall summary quality

---

## Modality-Specific Insights

### üé≠ Facial Analysis (209 features ‚Üí 780 correlations)

**Top Predictors:**
1. **disgust_min** ‚Üí Semantic_Similarity (œÅ = 0.746, p = 0.0014 **)
2. **happy_min** ‚Üí Semantic_Similarity (œÅ = 0.725, p = 0.0022 **)
3. **disgust_cv** ‚Üí Semantic_Similarity (œÅ = -0.643, p = 0.0097 **)
4. **quadrant_transitions** ‚Üí Overall_Percentage (œÅ = 0.544, p = 0.0361 *)
5. **surprise_min** ‚Üí Semantic_Similarity (œÅ = 0.536, p = 0.0396 *)

**Key Finding:** Facial features primarily predict **Semantic Similarity** (4 of top 5), suggesting facial expressions relate to content quality rather than coverage.

**Group Patterns:**
- **Opposing** group: Highest scores (60.2%), highest intensity (0.442)
- **Neutral** group: Medium scores (45.8%), medium intensity (0.415)
- **Similar** group: Lowest scores (38.3%), highest intensity (0.497) - paradox!

---

### üé§ Voice Analysis (375 features ‚Üí 1,404 correlations)

**Top Predictors:**
1. **volume_std_trend_direction** ‚Üí Topic_Coverage (œÅ = 0.769, p = 0.0008 ***)
2. **volume_range_trend_direction** ‚Üí Topic_Coverage (œÅ = 0.769, p = 0.0008 ***)
3. **pitch_mean_total_change** ‚Üí Topic_Coverage (œÅ = 0.701, p = 0.0036 **)
4. **volume_mean_trend_slope** ‚Üí Topic_Coverage (œÅ = 0.663, p = 0.0070 **)
5. **pitch_std_total_change** ‚Üí Topic_Coverage (œÅ = 0.649, p = 0.0089 **)

**Key Finding:** Voice features **dominate Topic_Coverage predictions** (73 significant correlations). Dynamic acoustic features (trends, changes) outperform static features.

**Strongest Negative Correlations:**
- **stress_max** ‚Üí Factual_Accuracy (œÅ = -0.694, p = 0.0041 **)
- **happy_max** ‚Üí Overall_Percentage (œÅ = -0.639, p = 0.0104 *)

**Group Patterns:**
- **Opposing** group: Highest scores (60.2%), highest pitch (186.8 Hz), fastest speech (5.9)
- **Similar** group: Lowest scores (38.3%), lowest pitch (127.8 Hz), slowest speech (3.6)

---

### üîÄ Fusion Analysis (273 features ‚Üí 252 correlations)

**Top Predictors:**
1. **combined_quadrant_transitions** ‚Üí Topic_Coverage (œÅ = 0.866, p = 0.0000 ***)
2. **combined_quadrant_transitions** ‚Üí Overall_Percentage (œÅ = 0.812, p = 0.0002 ***)
3. **fused_quadrant_transitions** ‚Üí Overall_Percentage (œÅ = 0.748, p = 0.0013 **)
4. **fused_quadrant_transitions** ‚Üí Topic_Coverage (œÅ = 0.719, p = 0.0025 **)
5. **combined_valence_total_change** ‚Üí Topic_Coverage (œÅ = 0.656, p = 0.0079 **)

**Key Finding:** Fusion achieves **highest correlations** (œÅ = 0.866) with fewer features. Combined features (averaging facial+voice) outperform pure fusion.

**Modality Agreement:**
- **valence_modality_agreement** ‚Üí Topic_Coverage (œÅ = 0.502, p = 0.0566)
- Facial-voice consistency predicts better summaries (near-significant)

**Group Patterns:**
- **Similar** group: Lowest scores (38.3%), **highest volatility** (0.167)
- **Opposing** group: Highest scores (60.2%), moderate volatility (0.154)
- **Neutral** group: Medium scores (45.8%), **lowest volatility** (0.131)

---

## Critical Insights

### 1. **Emotional Dynamics > Static Levels**
- Transitions, changes, and trends predict quality better than mean values
- **combined_quadrant_transitions** (œÅ = 0.866) beats all static features
- Voice pitch/volume **changes** stronger than absolute levels

### 2. **Topic Coverage is Most Predictable**
- Voice features: 25+ significant correlations with Topic_Coverage
- Fusion: Strongest correlation is with Topic_Coverage (œÅ = 0.866)
- Emotional volatility ‚Üí comprehensive topic coverage

### 3. **The Volatility Paradox**
- **Higher volatility ‚Üí LOWER scores** (Similar group)
- **Moderate volatility ‚Üí HIGHEST scores** (Opposing group)
- Optimal range exists: too stable = disengaged, too volatile = unfocused

### 4. **Modality Complementarity**
- Facial: Predicts **semantic quality** (content understanding)
- Voice: Predicts **topic coverage** (comprehensiveness)
- Fusion: Predicts **overall performance** (integration)

### 5. **Negative Emotions are Complex**
- **disgust_min** positive predictor (œÅ = 0.746) - baseline suppression helps
- **stress_max** negative predictor (œÅ = -0.694) - peak stress hurts accuracy
- **happy_max** negative predictor (œÅ = -0.639) - excessive happiness problematic

---

## Statistical Interpretation

### Correlation Strength Guidelines:
- **|œÅ| < 0.3:** Weak
- **|œÅ| 0.3-0.5:** Moderate
- **|œÅ| 0.5-0.7:** Strong
- **|œÅ| > 0.7:** Very Strong

### Significance Levels:
- `*` p < 0.05 (significant)
- `**` p < 0.01 (highly significant)
- `***` p < 0.001 (extremely significant)

### Effect Sizes:
- **Fusion** achieves **very strong** correlations (œÅ > 0.7) for 4 features
- **Voice** achieves **very strong** correlations (œÅ > 0.7) for 2 features
- **Facial** achieves **very strong** correlations (œÅ > 0.7) for 2 features

---

## Practical Applications

### For Thesis:
1. **Primary Finding:** Multimodal emotional dynamics predict cognitive performance (œÅ = 0.866)
2. **Mechanism:** Emotional transitions reflect engagement ‚Üí better information processing
3. **Optimal Profile:** Moderate volatility (Opposing group) balances focus and flexibility

### For Future Research:
1. Investigate **quadrant transitions** as engagement metric
2. Explore **optimal volatility range** for cognitive tasks
3. Validate **modality agreement** as consistency indicator
4. Test **real-time intervention** based on emotional dynamics

### For Conversation Design:
1. Monitor **voice volume trends** ‚Üí predict topic coverage quality
2. Track **emotional state changes** ‚Üí gauge comprehension depth
3. Detect **excessive happiness/stress** ‚Üí identify problematic states
4. Balance **facial baseline** with **voice dynamics** ‚Üí optimize engagement

---

## Files Generated

üìä **Data Files:**
- `facial_summary_merged.csv` - Merged facial + summary data (15 participants, 209 features)
- `voice_summary_merged.csv` - Merged voice + summary data (15 participants, 375 features)
- `fusion_summary_merged.csv` - Merged fusion + summary data (15 participants, 273 features)

üìà **Correlation Results:**
- `facial_summary_correlations.csv` - 780 correlations (5 significant)
- `voice_summary_correlations.csv` - 1,404 correlations (73 significant)
- `fusion_summary_correlations.csv` - 252 correlations (7 significant)

üé® **Visualizations:**
- `facial_summary_correlation_heatmap.png` - Facial-summary correlation matrix
- `voice_summary_correlation_heatmap.png` - Voice-summary correlation matrix
- `fusion_summary_correlation_heatmap.png` - Fusion-summary correlation matrix

---

## Advantages of Spearman Over Pearson

### Observed Benefits:
1. **Captured Non-Linear Relationships:** Quadrant transitions have monotonic (not linear) relationship with performance
2. **Robust to Extreme Scores:** Similar group's extreme volatility handled well
3. **Rank-Based Insights:** Relative emotional dynamics matter more than absolute values
4. **No Distribution Assumptions:** Small sample size (n=15) less problematic

### Trade-offs:
- Slightly lower statistical power for perfectly linear relationships
- Less intuitive interpretation (ranks vs. raw values)
- Cannot detect some complex non-monotonic patterns

**Conclusion:** Spearman is the **optimal choice** for this thesis given:
- Small sample size (n=15)
- Non-normal emotion distributions
- Likely non-linear relationships
- Presence of outliers (Similar group)

---

**Analysis Complete ‚úì**
